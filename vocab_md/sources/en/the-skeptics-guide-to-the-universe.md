---
source_name: The Skeptics' Guide to the Universe
source_description: A book
source_type: book

---

- **Memory Fallibility and False Memory Syndrome**

    There are numerous ways in which our memories are unreliable. In fact, entirely false memories can be easily fabricated, sometimes by misguided therapists.

    <div markdown="1" class="tagged-entries">

    en: fallibility: fallibility

    en: fabricate: fabricated

    </div>

- **Fallibility of Perception** 

    The act of perception is a complex, highly filtered, and active constructive process by your brain. We do not passively perceive external stimuli like a camera. This constructive process introduces many possibilities for illusion and misperception.

    <div markdown="1" class="tagged-entries">

    en: stimulus: stimuli

    en: fallibility: fallibility

    </div>

- **Pareidolia**

    Pareidolia refers to the process of perceiving an image in random noise, such as seeing a face in the craters and maria of the moon.

    <div markdown="1" class="tagged-entries">

    en: pareidolia: pareidolia

    </div>

- But this phenomenon goes much deeper than just children imagining a sky menagerie, and it reflects how our brains process and interpret information.

    <div markdown="1" class="tagged-entries">

    en: menagerie: menagerie

    en: phenomenon: phenomenon

    </div>

- The term for this phenomenon is pareidolia, which refers to the perception of familiar yet meaningless patterns in random stimuli or noise. It usually applies to seeing visual patterns, but sometimes the term is used to refer to other sensations, such as sound (in which case it might be called, fittingly, audio pareidolia).

    <div markdown="1" class="tagged-entries">

    en: pareidolia: pareidolia

    en: stimulus: stimuli

    </div>

- The technical term for the more general phenomenon of seeing patterns where they do not exist is apophenia, the tendency to see illusory patterns in noisy data.

    <div markdown="1" class="tagged-entries">

    en: phenomenon: phenomenon

    en: apophenia: apophenia

    </div>

- When NASA took a higher resolution image in 1998, it became obvious that the face was just an eroded pile of rocky detritus, no more an intentional face than the bumps on your ceiling.

    <div markdown="1" class="tagged-entries">

    en: detritus: detritus

    </div>

- Pareidolia can be fun, but if you aren't aware of our penchant for and love of patterns, an interesting and diverting illusion can feed into a delusion. As we will see, some illusory patterns are more nefarious than just seeing a bunny rabbit in a cloud.

    <div markdown="1" class="tagged-entries">

    en: pareidolia: pareidolia

    en: nefarious: nefarious

    </div>

- **Hyperactive Agency Detection**

    Hyperactive agency detection (HADD) is the tendency to interpret events as if they were the deliberate intent of a conscious agent rather than the product of natural forces or unguided chaotic events.

    <div markdown="1" class="tagged-entries">

    en: hyperactive agency detection: hyperactive agency detection

    en: deliberate: deliberate

    en: conscious: conscious

    en: chaotic: chaotic

    </div>

- Understanding that HADD is an intrinsic part of human nature is part of the core knowledge base of the skeptic.

    <div markdown="1" class="tagged-entries">

    en: intrinsic: intrinsic

    </div>

- We imbue agents with an essence&mdash;a unique living force&mdash;even as infants. Objects are just generic things and are totally interchangeable, while agents have their own unique essence. This reinforces the notion that the distinction we make is not between living and nonliving so much as agent versus object.

    <div markdown="1" class="tagged-entries">

    en: imbue: imbue

    en: interchangeable: interchangeable

    </div>

- **Hypnagogia**

    Hypnagogia is a neurological phenomenon in which the dreaming and waking states are fused, producing unusual experiences often mistaken for paranormal ones.

    <div markdown="1" class="tagged-entries">

    en: hypnagogia: hypnagogia

    en: neurological: neurological

    en: phenomenon: phenomenon

    en: paranormal: paranormal

    </div>

- **Ideomotor Effect**

    The ideomotor effect is an involuntary subconscious subtle muscle movement driven by expectation, which creates the illusion that the movement is due to an external force.

    <div markdown="1" class="tagged-entries">

    en: ideomotor effect: ideomotor effect

    en: subconscious: subconscious

    </div>

- Before hypothesizing about spirits, new forces, or supernatural abilities, consider that&mdash;just maybe&mdash;your brain (like the brain of every other human on the planet) has some quirks and foibles. That is the meaning of neuropsychological humility.

    <div markdown="1" class="tagged-entries">

    en: hypothesize: hypothesizing

    en: quirk: quirks

    en: foible: foibles

    en: neuropsychological: neuropsychological

    en: humility: humility

    </div>

- **Metacognition**

    Even when our memory and perception are working reliably, we still have to reason with the information we have. That is a trip down a twisting road with blind alleys and many pitfalls. Fortunately, psychologists have spent decades working out many of the ways our thinking goes astray.

    <div markdown="1" class="tagged-entries">

    en: metacognition: metacognition

    </div>

- The hope to "beat the odds" is based on logical fallacies and cognitive biases. Superstition and belief in "luck" (which is highly encouraged by casinos) are rampant. The casinos themselves don't trust in luck&mdash;they know that cold, hard math will grant them a steady flow of income.

    <div markdown="1" class="tagged-entries">

    en: fallacy: fallacies

    en: bias: biases

    en: rampant: rampant

    en: math: math

    </div>

- **Dunning-Kruger Effect**

    The Dunning-Kruger effect describes the inability to evaluate one's own competency, leading to a general tendency to overestimate one's abilities.

    <div markdown="1" class="tagged-entries">

    en: Dunning-Kruger effect: Dunning-Kruger effect

    en: ability: abilities

    en: competency: competency

    </div>

- Remember the character David Brent, played by Ricky Gervais in the British version of _The Office_ (an analogous character was played by Steve Carell in the American version)? David is a classic character because he is only a slight exaggeration of people we all know in real life&mdash;too incompetent and full of himself to have any idea how thoroughly incompetent he actually is.

    <div markdown="1" class="tagged-entries">

    en: analogous: analogous

    en: incompetent: incompetent

    </div>

- As we try to make sense of the world, we work with our existing knowledge and paradigms. We formulate ideas then systematically seek out information that confirms those ideas. We dismiss contrary information as exceptions. We interpret ambiguous experiences as in line with our theories. We make subjective judgements that further reinforce our beliefs.

    <div markdown="1" class="tagged-entries">

    en: paradigm: paradigms

    en: knowledge: knowledge

    </div>

- In the end we are left with a powerful sense of knowledge&mdash;but it's false knowledge. Confirmation bias leads to a high level of confidence. We feel deep in our gut that we are right. And when confronted by someone saying we're wrong or promoting an alternate view, there is a tendency to become defensive, even hostile.

    <div markdown="1" class="tagged-entries">

    en: knowledge: knowledge

    en: alternate: alternate

    </div>

- We need to substitute a logical and scientific process for the one Dunning describes above.

    <div markdown="1" class="tagged-entries">

    en: substitute X for Y: substitute a logical and scientific process for the one Dunning describes above

    </div>

- Now realize that you are as ignorant as the average person is in every other area of knowledge in which you are not expert. The Dunning-Kruger effect is not just about dumb people not realizing how dumb they are. It is about basic human psychology and cognitive biases. Dunning-Kruger applies to everyone.

    <div markdown="1" class="tagged-entries">

    en: bias: biases

    en: Dunning-Kruger effect: Dunning-Kruger

    </div>

- In addition to the various aspects of critical thinking, self assessment is a skill we can strive to develop specifically. But a good rule of thumb is to err on the side of humility. If you assume that you know relatively less than what you think you do and that there is more knowledge than you are aware of, you will usually be correct.

    <div markdown="1" class="tagged-entries">

    en: err: err

    en: humility: humility

    en: knowledge: knowledge

    en: rule of thumb: rule of thumb

    </div>

- **Motivated Reasoning**

    Motivated reasoning is the biased process we use to defend a position, ideology, or belief that we hold with emotional investment.

    <div markdown="1" class="tagged-entries">

    en: motivated reasoning: motivated reasoning

    en: ideology: ideology

    en: biased: biased

    </div>

- > Some information, some ideas, feel like our allies. We want them to win. We want to defend them. And other information or ideas are the enemy, and we want to shoot them down. &mdash;Julia Galef

    <div markdown="1" class="tagged-entries">

    en: information: information

    en: ally: allies

    </div>

- Have you ever ben in a heated political discussion? Heck, have you ever interacted with other human beings? Then you are likely familiar with the frustration of someone else twisting logic, cherry-picking or distorting facts, and being generally biased in their defense of a position. Of course, here's the thing: You do it too.

    <div markdown="1" class="tagged-entries">

    en: biased: biased

    en: cherry-picking: cherry-picking

    en: interact: interacted

    en: human being: human beings

    </div>

- We tend to follow a Bayesian approach, meaning that we update our beliefs as new information comes to our attention. If we are told that some historical fact is different than what we remember, we'll quickly change our beliefs about that historical fact. Further, the more information we have about something, and therefore the more solid our belief, the more slowly we will change that belief. We don't just change from one thing to the next, we incorporate the new information with our old information.

    <div markdown="1" class="tagged-entries">

    en: information: information

    en: belief: beliefs, belief

    en: Bayesian: Bayesian

    </div>

- Motivated reasoning is triggered by what psychologists call cognitive dissonance.

    <div markdown="1" class="tagged-entries">

    en: cognitive dissonance: cognitive dissonance

    en: trigger: triggered

    </div>

- In general, political opinions tend to fall into the "sacred cow" category. People tend to identify with their political tribe and want to believe that their tribe is virtuous and smart, where the other tribe is mostly made of lying idiots. Of course, these dichotomies occur on a spectrum. You can have a little bit of an emotional attachment to a belief, or it can be fundamental to your worldview and identity. You can be a little tribal in your political views, or hyperpartisan.

    <div markdown="1" class="tagged-entries">

    en: political: political

    en: sacred cow: sacred cow

    en: virtuous: virtuous

    en: dichotomy: dichotomies

    en: spectrum: spectrum

    </div>

- Here is another important thing to keep in mind: If the premises of an argument are true and sufficiently complete, and the logic is valid (in which case the argument is said to be "sound"), the the conclusion must be true.

    <div markdown="1" class="tagged-entries">

    en: premise: premises

    en: sound argument: the argument is said to be "sound"

    </div>

- So, if an argument is sound, the conclusion is true. However, the converse is not true. An unsound argument can still have a conclusion that happens to be true, even though the argument doesn't support it. Someone might argue that the sun is a sphere because spheres are pretty&mdash;that isn't a sound argument, but the conclusion is still true.

    <div markdown="1" class="tagged-entries">

    en: sound argument: sound argument

    </div>

- There are four types of potential problems with premises. The first, and most obvious, is that a premise can be wrong.

    <div markdown="1" class="tagged-entries">

    en: premise: premises, premise

    </div>

- Another type of premise error occurs when one or more premises are unwarranted assumptions. The premise may or may not be true, but it hasn't been established sufficiently to serve as a premise for an argument.

    <div markdown="1" class="tagged-entries">

    en: premise: premise, premises

    en: assumption: assumptions

    </div>

-  The third type of premise difficulty is the most insidious: the hidden premise. Obviously, if a disagreement is based upon a hidden premise, then the disagreement will be irresolvable.

    <div markdown="1" class="tagged-entries">

    en: insidious: insidious

    en: irresolvable: irresolvable

    </div>

- The fourth potential problem with premises, one that can be very subtle, is when a premise contains a subjective judgement.

    <div markdown="1" class="tagged-entries">

    en: premise: premise, premises

    en: subjective: subjective

    </div>

- In fact, every time someone tries to form an argument to support a conclusion that isn't true, they must either employ a false premise or a logical fallacy. Remember, a sound argument (one with true premises and valid logic) cannot lead to a false conclusion. So they have no choice but to use false premises or bad logic if they want to defend a false conclusion.

    <div markdown="1" class="tagged-entries">

    en: premise: premise

    en: fallacy: fallacy

    en: sound argument: sound argument

    </div>

- **Non Sequitur**

    From Latin, this term translates to "it doesn't follow," and it refers to an argument in which the conclusion does not necessarily follow from the premises

    <div markdown="1" class="tagged-entries">

    en: non sequitur: non sequitur

    en: premise: premises

    </div>

- **Argument from Authority**

    The basic structure of such arguments is as follows: Professor X believes A, Professor X speaks from authority, therefore A is true.

    <div markdown="1" class="tagged-entries">

    en: argument from authority: argument from authority

    </div>

- **Argument from Final Outcome**

    Such arguments (also called teleological) are based on a reversal of cause and effect, because they argue that something is caused by the ultimate effect that it has or the purpose that it serves.

    <div markdown="1" class="tagged-entries">

    en: argument from final outcome: argument from final outcome

    en: teleological: teleological

    </div>

- **Post Hoc Ergo Propter Hoc**

    This is perhaps the most common of logical fallacies. It follows the basic format of **A** preceded **B**, therefore **A** caused **B**, assuming cause and effect for two events just because they are temporally related (the Latin translates to "after this, therefore because of this").

    <div markdown="1" class="tagged-entries">

    en: post hoc ergo propter hoc: post hoc ergo propter hoc

    en: fallacy: fallacies

    en: precede: precede

    en: temporally: temporally

    </div>

- **Confusing Correlation with Causation**

    This is similar to the post hoc fallacy in that is assumes cause and effect for two variables simply because they occur together. This fallacy is often used to give a statistical correlation a causal interpretation.

    <div markdown="1" class="tagged-entries">

    en: post hoc ergo propter hoc: post hoc

    en: fallacy: fallacy

    </div>

- In essence there are always four possible interpretations of any apparent correlation. The first is that the correlation is not causal at all. The second is that A causes B. The third is that B causes A. The fourth is that A and B are both caused by another variable, C. It's helpful to go through all such possibilities before concluding that any one causal pattern is true.

    <div markdown="1" class="tagged-entries">

    en: correlation: correlation

    </div>

- **Special Pleading, or Ad Hoc Reasoning**

    This is a subtle fallacy, often difficult to recognize. In essence, it's the arbitrary introduction of new elements into an argument in order to jerry-rig that argument so it appears valid.

    <div markdown="1" class="tagged-entries">

    en: ad hoc reasoning: ad hoc reasoning

    en: fallacy: fallacy

    en: jerry-rig: jerry-rig

    </div>

- **Tu Quoque**

    The Latin phrase _tu quoque_ translates to "you too." This is an attempt to justify wrong action because someone else does the same thing: "My evidence may be bad, but so is yours."

    <div markdown="1" class="tagged-entries">

    en: tu quoque: tu quoque

    </div>

- **Ad Hominem**

    An ad hominem argument is one that attempts to counter another's claims or conclusions by attacking the person rather than by addressing the argument itself.

    <div markdown="1" class="tagged-entries">

    en: ad hominem: ad hominem

    </div>

- The term "poisoning the well" refers to a form of ad hominem fallacy. This is an attempt to discredit the argument of another by implying that they possess un unsavory trait, or that they're affiliated with beliefs or people that are wrong or unpopular. A well-known form of this, which has its own name&mdash;Godwin's Law or the reductio ad Hitlerum&mdash;refers to an attempt at poisoning the well by drawing an analogy between another's position and Hitler or the Nazis.

    <div markdown="1" class="tagged-entries">

    en: poisoning the well: poisoning the well

    en: ad hominem: ad hominem

    en: fallacy: fallacy

    </div>

- It should be noted, however, that not all name-calling is a logical fallacy. If I impolitely state that someone with whom I disagree is a jackass, that's not an ad hominem logical fallacy. If I say their argument is wrong because they are a jackass, then that is a fallacy.

    <div markdown="1" class="tagged-entries">

    en: ad hominem: ad hominem

    en: fallacy: fallacy

    </div>

- **Ad Ignorantiam**

    The argument from ignorance basically states that a specific belief is true because we don't know that it isn't true.

    <div markdown="1" class="tagged-entries">

    en: ad ignorantiam: ad ignorantiam

    </div>

- Often the argument from ignorance is defended with the adage "Absence of evidence is not evidence of absence." While this sounds pithy, it's not strictly true. Absence of evidence is, in fact, evidence of absence. It's just not absolute proof of absence.

    <div markdown="1" class="tagged-entries">

    en: pithy: pithy

    en: adage: adage

    </div>

- **False Continuum**

    A false continuum is the idea that because there is no definitive demarcation line between two extremes, the distinction between the extremes is therefore not real or meaningful.

    <div markdown="1" class="tagged-entries">

    en: false continuum: false continuum

    en: demarcation: demarcation

    </div>

- **False Dichotomy**

    This fallacy involves arbitrarily reducing a set of many possibilities to only two. For example, evolution isn't possible, so we must have been created.

    <div markdown="1" class="tagged-entries">

    en: false dichotomy: false dichotomy

    </div>

- **Cognitive Biases and Heuristics**

    Cognitive biases are flaws in the way our brains process information. Heuristics are similar&mdash;they're rules of thumb or mental shortcuts that are not reliably true and therefore also lead to biased thinking.

    <div markdown="1" class="tagged-entries">

    en: hueristic: hueristics

    </div>

- Cognitive flaws and biases can be mitigated by metacognition, which is, simply put, thinking about thinking. Skepticism is largely a systematic effort in metacognition, which means understanding how we think and avoiding common mental pitfalls.

    <div markdown="1" class="tagged-entries">

    en: mitigate: mitigated

    en: metacognition: metacognition

    en: skepticism: skepticism

    </div>

- **Confirmation Bias**

    Confirmation bias is the tendency of individuals to seek out or interpret new information as support for previously held notions or beliefs, even when such interpretations don't hold up to statistical scrutiny.

    <div markdown="1" class="tagged-entries">

    en: confirmation bias: confirmation bias

    en: scrutiny: scrutiny

    </div>

- Here's the task: There are four cards on a table before you. They each have a letter on one side and a number on the other. I have a hypothesis&mdash;every card that has a vowel on one side has an even number on the other. The four cards are show A, 7, D, and 4.

    The question for you is this: Which cards do I need to flip over in order to test my hypothesis? The correct answer is that you need to turn over A and 7. If A doesn't have an even number on the other side, or 7 has a vowel, the hypothesis is wrong.

    <div markdown="1" class="tagged-entries">

    en: hypothesis: hypothesis

    </div>

- But the core lesson remains&mdash;if you want to test your hypothesis, try to prove it wrong. Do not only look for evidence to prove it right.

    <div markdown="1" class="tagged-entries">

    en: hypothesis: hypothesis

    </div>

- **Fundamental Attribution Error**

    The fundamental attribution error is a cognitive bias in which we ascribe other people's actions to internal factors such as personality while rationalizing our own actions as being the result of external factors beyond our control.

    <div markdown="1" class="tagged-entries">

    en: ascribe: ascribe

    en: fundamental attribution error: fundamental attribution error

    en: rationalize: rationalizing

    </div>

- Viewed from the outside, you can make anything strange look sinister and ascribe internal motivations to people. Knowing the circumstances is often enough to shed light on their behavior.

    <div markdown="1" class="tagged-entries">

    en: ascribe: ascribe

    en: shed light on something: shed light on their behavior

    </div>

- Probability puzzles are not exactly in high demand in our culture. I don't suspect that Selvin's letter to the editor went viral in the seventies; nor did the game show itself popularize the eponymous puzzle. The immense popularity of the Monty Hall problem can be directly traced to a genius writing for _Parade_ magazine.

    <div markdown="1" class="tagged-entries">

    en: eponymous: eponymous

    </div>

- I think the most parsimonious explanation for all scientific knowledge is that there is a an actual real physical universe out there.

    <div markdown="1" class="tagged-entries">

    en: parsimonious: parsimonious

    </div>

- **Postmodernism**

    Postmodernism, as it applies to science, is the philosophical position that science is nothing more than a cultural narrative and therefore has no special or privileged relationship with the truth.

    <div markdown="1" class="tagged-entries">

    en: postmodernism: postmodernism

    en: narrative: narrative

    </div>

- Postmodernism, in practice, is the ultimate sour grapes of science deniers&mdash;"Well, all science is socially constructed anyway." Add in a little talk about fascism and oppression and you can make it all seem socially conscious.

    <div markdown="1" class="tagged-entries">

    en: postmodernism: postmodernism

    en: conscious: conscious

    en: oppression: oppression

    </div>

- Pseudoscientists, because they are invested in a desired conclusion, will give only perfunctory consideration of competing hypotheses. Often one or two token alternatives will be put forward and summarily shot down, leaving the desired belief as the only possibility.

    <div markdown="1" class="tagged-entries">

    en: perfunctory: perfunctory

    en: summarily: summarily

    </div>

- **Denialism**

    Denialism or science denial refers to the motivated denial of accepted science using a series of invalid strategies.

    <div markdown="1" class="tagged-entries">

    en: denialism: denialism

    </div>

- In fact denialism is a subset of pseudoscience, on that tries to cloak itself in the language of skepticism while eschewing the actual process of scientific skepticism. Denialism exists on a spectrum with skepticism, without a clear demarcation between the two.

    <div markdown="1" class="tagged-entries">

    en: eschew: eschewing

    en: spectrum: spectrum

    en: demarcation: demarcation

    </div>

- P-hacking leads to a tremendous waste of scientific resources. It's incredibly inefficient, flooding the literature with spurious results that probably won't be replicated. It's also almost entirely ignored when reporting science to the public. All the public hears is, "Scientists report a significant result," but most of what gets relayed as excited scientific breakthroughs is simply crap cluttering up the scientific journals.

    <div markdown="1" class="tagged-entries">

    en: spurious: spurious

    </div>

- **Conspiracy Theories**

    A conspiracy theory, or more precisely a grand conspiracy, is a belief system that involves at its core the claim that a vastly powerful group is carrying out a deception against the public for their own nefarious ends.

    <div markdown="1" class="tagged-entries">

    en: conspiracy: conspiracy

    en: nefarious: nefarious

    </div>

- Conspiracy thinking is arguably the confluence of many of the logical fallacies and cognitive biases that we have already discussed. In many ways it is the "one ring to rule them all" of faulty thinking.

    <div markdown="1" class="tagged-entries">

    en: conspiracy: conspiracy

    en: confluence: confluence

    en: logical fallacy: logical fallacies

    en: cognitive bias: cognitive biases

    </div>

- The grand conspiracy forms a triangle of sorts. First there are the conspirators. This is typically a large, powerful, and shadowy organization with vast resources and control. They need to be powerful in order to fake moon landings, poison the public through jet exhaust, or frame terrorists for 9/11. Then there are the conspiracy theorists, an "Army of Light" that is able to see through the conspiracy (because they are just so clever). Finally, there is everyone else, the dupes or "sheeple" who believe the standard explanation of history and current events.

    <div markdown="1" class="tagged-entries">

    en: grand conspiracy: grand conspiracy

    en: conspirator: conspirators

    en: conspiracy theorist: conspiracty theorists

    en: conspiracy: conspiracy

    en: dupe: dupes

    </div>

